{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57099c5b",
   "metadata": {},
   "source": [
    "# Tutorial on ensemble history matching and optimisation\n",
    "\n",
    "Copyright Patrick N. Raanes, NORCE, 2020.\n",
    "\n",
    "This (Jupyter/Python) notebook presents\n",
    "a tutorial on history matching (HM) using ensemble methods.\n",
    "\n",
    "This is a work in progress.\n",
    "Details may be lacking.\n",
    "Don't hesitate to send me an email with any questions you have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d56e6",
   "metadata": {},
   "source": [
    "## Jupyter notebooks\n",
    "the format used for these tutorials.\n",
    "Notebooks combine **cells** of code (Python) with cells of text (markdown).\n",
    "The exercises in these tutorials only require light Python experience.\n",
    "For example, edit the cell below (double-click it),\n",
    "insert your name,\n",
    "and run it (press \"Run\" in the toolbar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfacff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Batman\"\n",
    "print(\"Hello world! I'm \" + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fef822",
   "metadata": {},
   "source": [
    "You will likely be more efficient if you know these\n",
    "**keyboard shortcuts** to interact with cells:\n",
    "\n",
    "| Navigate                      |    | Edit              |    | Exit           |    | Run                              |    | Run & go to next                  |\n",
    "| -------------                 | -- | ----------------- | -- | --------       | -- | -------                          | -- | -----------------                 |\n",
    "| <kbd>↓</kbd> and <kbd>↑</kbd> |    | <kbd>Enter</kbd>  |    | <kbd>Esc</kbd> |    | <kbd>Ctrl</kbd>+<kbd>Enter</kbd> |    | <kbd>Shift</kbd>+<kbd>Enter</kbd> |\n",
    "\n",
    "When you open a notebook it starts a **session (kernel/runtime)**\n",
    "of Python in the background.\n",
    "All of the Python code cells (in a given notebook) are connected\n",
    "(they use the same Python kernel and thus share variables, functions, and classes).\n",
    "Thus, the **order** in which you run the cells matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4077d17",
   "metadata": {},
   "source": [
    "First off, since you're running this on Colab, execute the following cell to download and install the project's requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- https://raw.githubusercontent.com/patricknraanes/HistoryMatching/master/colab_bootstrap.sh | bash -s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e5c11",
   "metadata": {},
   "source": [
    "One thing you must know is how to **restart** the Python session,\n",
    "which clears all of your variables, functions, etc,\n",
    "so that you can start over.\n",
    "Test this now by going through the top menu bar:\n",
    "`Kernel` → `Restart & Clear Output`.\n",
    "But rembember to run the above cell again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562831e",
   "metadata": {},
   "source": [
    "There is a huge amount of libraries available in **Python**,\n",
    "including the popular `scipy` (with `numpy` at its core) and `matplotlib` packages.\n",
    "These are imported (and abbreviated) as `sp`, `np`, and `mpl` and `plt`.\n",
    "Try them out by running the following, which illustrates some algebra\n",
    "using syntax reminiscent of Matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mpl_setup\n",
    "mpl_setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de43331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy's arrays for vectors and matrices. Example constructions:\n",
    "a  = np.arange(10)  # Alternatively: np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "Id = 2*np.eye(10)   # Alternatively: np.diag(2*np.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indexing examples:\")\n",
    "print(\"a         =\", a)\n",
    "print(\"a[3]      =\", a[3])\n",
    "print(\"a[0:3]    =\", a[0:3])\n",
    "print(\"a[:3]     =\", a[:3])\n",
    "print(\"a[3:]     =\", a[3:])\n",
    "print(\"a[-1]     =\", a[-1])\n",
    "print(\"Id[:3,:3] =\", Id[:3, :3], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinear algebra examples:\")\n",
    "print(\"100+a  =\", 100+a)\n",
    "print(\"Id@a   =\", Id@a)\n",
    "print(\"Id*a   =\", Id*a, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c765390",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Plotting example\")\n",
    "plt.ylabel(\"$i \\\\, x^2$\")\n",
    "for i in range(4):\n",
    "    plt.plot(i * a**2, label=\"i = %d\" % i)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a27b23",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12cb107",
   "metadata": {},
   "source": [
    "Run the following cells to import some tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64667622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sla\n",
    "from matplotlib import ticker\n",
    "from mpl_tools.fig_layout import freshfig\n",
    "from numpy.random import randn\n",
    "from numpy import sqrt\n",
    "from struct_tools import DotDict as Dict\n",
    "from tqdm.auto import tqdm as progbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c2818",
   "metadata": {},
   "source": [
    "and the model, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c57a72",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import geostat\n",
    "import simulator\n",
    "import simulator.plotting as plots\n",
    "from simulator import simulate\n",
    "from tools import RMS, RMS_all, center, mean0, pad0, svd0, inflate_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.COORD_TYPE = \"absolute\"\n",
    "cmap = plt.get_cmap(\"jet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570df8b",
   "metadata": {},
   "source": [
    "... and initialize some data containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permeability\n",
    "perm = Dict()\n",
    "\n",
    "# Production (water saturation)\n",
    "prod = Dict(\n",
    "    past   = Dict(),\n",
    "    future = Dict(),\n",
    ")\n",
    "\n",
    "# Water saturation\n",
    "wsat = Dict(\n",
    "    initial = Dict(),\n",
    "    past    = Dict(),\n",
    "    future  = Dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d44b05",
   "metadata": {},
   "source": [
    "Enable exact reproducibility by setting random generator seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4238c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(4)  # very easy\n",
    "# seed = np.random.seed(5)  # hard\n",
    "# seed = np.random.seed(6)  # very easy\n",
    "# seed = np.random.seed(7)  # easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b8f2c",
   "metadata": {},
   "source": [
    "## Model and case specification\n",
    "The reservoir model, which takes up about 100 lines of python code, is a 2D, two-phase, immiscible, incompressible simulator using TPFA. It was translated from the matlab code here http://folk.ntnu.no/andreas/papers/ResSimMatlab.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a591a",
   "metadata": {},
   "source": [
    "We will estimate the log permeability field. The data will consist in the water saturation of the production (at the well locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28243c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = simulator.ResSim(Nx=20, Ny=20, Lx=2, Ly=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25fb7fe",
   "metadata": {},
   "source": [
    "#### Permeability sampling\n",
    "We work with log permeabilities, which can (in principle) be Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e6559",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def sample_log_perm(N=1):\n",
    "    lperms = geostat.gaussian_fields(model.mesh(), N, r=0.8)\n",
    "    return lperms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e9687",
   "metadata": {},
   "source": [
    "The transformation of the parameters to model input is effectively part of the forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3896b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def f_perm(x):\n",
    "    return .1 + np.exp(5*x)\n",
    "    # return 1000*np.exp(3*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d58ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def set_perm(model, log_perm_array):\n",
    "    p = f_perm(log_perm_array)\n",
    "    p = p.reshape(model.shape)\n",
    "    model.Gridded.K = np.stack([p, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff689c2",
   "metadata": {},
   "source": [
    "Here we sample the permeabilitiy of the (synthetic) truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm.Truth = sample_log_perm()\n",
    "set_perm(model, perm.Truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9363b13",
   "metadata": {},
   "source": [
    "#### Well specification\n",
    "We here specify the wells as point sources and sinks, giving their placement and flux.\n",
    "\n",
    "The boundary conditions are of the Dirichlet type, specifying zero flux. The source terms must therefore equal the sink terms. This is ensured by the `config_wells` function used below. Note that `config_wells` takes *relative* values (between 0 and 1) for x and y locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f27bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual well specification\n",
    "# model.init_Q(\n",
    "#     #     x    y     rate\n",
    "#     inj =[\n",
    "#         [0.50, 0.50, 1.00],\n",
    "#     ],\n",
    "#     prod=[\n",
    "#         [0.10, 0.10, 1.00],\n",
    "#         # [0.10, 0.50, 1.00],\n",
    "#         [0.10, 0.90, 1.00],\n",
    "#         # [0.50, 0.10, 1.00],\n",
    "#         # [0.50, 0.50, 1.00],\n",
    "#         # [0.50, 0.90, 1.00],\n",
    "#         [0.90, 0.10, 1.00],\n",
    "#         # [0.90, 0.50, 1.00],\n",
    "#         [0.90, 0.90, 1.00],\n",
    "#     ]\n",
    "# );\n",
    "\n",
    "# Wells on a grid\n",
    "wells = [.1, .9]\n",
    "wells = np.dstack(np.meshgrid(wells, wells)).reshape((-1, 2))\n",
    "rates = np.ones((len(wells), 1))\n",
    "model.config_wells(\n",
    "    inj  = [[0.50, 0.50, 1.00]],\n",
    "    prod = np.hstack((wells, rates)),\n",
    ");\n",
    "\n",
    "# # Random well configuration\n",
    "# model.init_Q(\n",
    "#     inj =rand(1, 3),\n",
    "#     prod=rand(8, 3)\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160d353",
   "metadata": {},
   "source": [
    "#### Plot true field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f9025",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = freshfig(110)\n",
    "# cs = plots.field(model, ax, perm.Truth)\n",
    "cs = plots.field(model, ax, f_perm(perm.Truth), locator=ticker.LogLocator())\n",
    "plots.well_scatter(model, ax, model.producers, inj=False)\n",
    "plots.well_scatter(model, ax, model.injectors, inj=True)\n",
    "fig.colorbar(cs)\n",
    "fig.suptitle(\"True field\");\n",
    "plt.pause(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd799dc",
   "metadata": {},
   "source": [
    "#### Define obs operator\n",
    "There is no well model. The data consists purely of the water saturation at the location of the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ed2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_inds = [model.xy2ind(x, y) for (x, y, _) in model.producers]\n",
    "def obs(water_sat):\n",
    "    return [water_sat[i] for i in obs_inds]\n",
    "obs.length = len(obs_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33f63d",
   "metadata": {},
   "source": [
    "#### Simulation to generate the synthetic truth evolution and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsat.initial.Truth = np.zeros(model.M)\n",
    "T     = 1\n",
    "dt    = 0.025\n",
    "nTime = round(T/dt)\n",
    "wsat.past.Truth, prod.past.Truth = simulate(\n",
    "    model.step, nTime, wsat.initial.Truth, dt, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368a800",
   "metadata": {},
   "source": [
    "##### Animation\n",
    "Run the code cell below to get an animation of the oil saturation evoluation.\n",
    "Injection (resp. production) wells are marked with triangles pointing down (resp. up).\n",
    "\n",
    "<mark><font size=\"-1\"> <em>Note:</em>\n",
    "Can take (up to) a minute to display figure.\n",
    "</font></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef8bd1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ani = plots.dashboard(model, wsat.past.Truth, prod.past.Truth, animate=True, title=\"Truth\");\n",
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20a95d",
   "metadata": {},
   "source": [
    "#### Noisy obs\n",
    "In reality, observations are never perfect. To account for this, we corrupt the observations by adding a bit of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a929560",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "prod.past.Noisy = prod.past.Truth.copy()\n",
    "nProd = len(model.producers)  # num. of obs (per time)\n",
    "R = 1e-3 * np.eye(nProd)\n",
    "for iT in range(nTime):\n",
    "    prod.past.Noisy[iT] += sqrt(R) @ randn(nProd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f73f85",
   "metadata": {},
   "source": [
    "Plot of observations (and their noise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = freshfig(120)\n",
    "hh_y = plots.production1(ax, prod.past.Truth, obs=prod.past.Noisy)\n",
    "plt.pause(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa23e8",
   "metadata": {},
   "source": [
    "## Prior\n",
    "The prior ensemble is generated in the same manner as the (synthetic) truth, using the same mean and covariance.  Thus, the members are \"statistically indistinguishable\" to the truth. This assumption underlies ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1261a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "perm.Prior = sample_log_perm(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that field (before transformation) is Gaussian with (expected) mean 0 and variance 1.\n",
    "print(\"Prior mean:\", np.mean(perm.Prior))\n",
    "print(\"Prior var.:\", np.var(perm.Prior))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc3e54",
   "metadata": {},
   "source": [
    "Let us inspect the parameter values in the form of their histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fa6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = freshfig(130, figsize=(12, 3))\n",
    "for label, data in perm.items():\n",
    "\n",
    "    ax.hist(\n",
    "        f_perm(data.ravel()),\n",
    "        f_perm(np.linspace(-3, 3, 32)),\n",
    "        # \"Downscale\" ens counts by N. Necessary because `density` kw\n",
    "        # doesnt work \"correctly\" with log-scale.\n",
    "        weights = (np.ones(model.M*N)/N if label != \"Truth\" else None),\n",
    "        label=label, alpha=0.3)\n",
    "\n",
    "    ax.set(xscale=\"log\", xlabel=\"Permeability\", ylabel=\"Count\")\n",
    "    ax.legend();\n",
    "plt.pause(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f16f9f",
   "metadata": {},
   "source": [
    "The above histogram should be Gaussian histogram if f_perm is purely exponential:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f14015",
   "metadata": {},
   "source": [
    "Below we can see some realizations (members) from the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4861c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.fields(model, 140, plots.field, perm.Prior,\n",
    "             figsize=(14, 5), cmap=cmap,\n",
    "             title=\"Prior -- some realizations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc62b2",
   "metadata": {},
   "source": [
    "#### Eigenvalue specturm\n",
    "In practice, of course, we would not be using an explicit `Cov` matrix when generating the prior ensemble, because it would be too large.  However, since this synthetic case in being made that way, let's inspect its spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, svals, VT = sla.svd(perm.Prior)\n",
    "ii = 1+np.arange(len(svals))\n",
    "fig, ax = freshfig(150, figsize=(12, 5))\n",
    "ax.loglog(ii, svals)\n",
    "# ax.semilogx(ii, svals)\n",
    "ax.grid(True, \"minor\", axis=\"x\")\n",
    "ax.grid(True, \"major\", axis=\"y\")\n",
    "ax.set(xlabel=\"eigenvalue #\", ylabel=\"var.\",\n",
    "       title=\"Spectrum of initial, true cov\");\n",
    "plt.pause(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba860385",
   "metadata": {},
   "source": [
    "## Assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37d257",
   "metadata": {},
   "source": [
    "#### Exc (optional)\n",
    "Before going into iterative methods, we note that\n",
    "the ensemble smoother (ES) is favoured over the ensemble Kalman smoother (EnKS) for history matching. This may come as a surprise, because the EnKS processes the observations sequentially, like the ensemble Kalman filter (EnKF), not in the batch manner of the ES. Because sequential processing is more gradual, one would expect it to achieve better accuracy than batch approaches. However, the ES is preferred because the uncertainty in the state fields is often of less importance than the uncertainty in the parameter fields. More imperatively, (re)starting the simulators (e.g. ECLIPSE) from updated state fields (as well as parameter fields) is a troublesome affair; the fields may have become \"unphysical\" (or \"not realisable\") because of the ensemble update, which may hinder the simulator from producing meaningful output (it may crash, or have trouble converging). On the other hand, by going back to the parameter fields before geological modelling (using fast model update (FMU)) tends to yield more realistic parameter fields. Finally, since restarts tend to yield convergence issues in the simulator the following inequality is usually large.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\t\\max_n \\sum_{t}^{} T_t^n < \\sum_{t}^{} \\max_n T_t^n,\n",
    "\t\\label{eqn:max_sum_sum_max}\n",
    "\\end{align}\n",
    "$$\n",
    "skjervheim2011ensemble\n",
    "Here, $T_t^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd6ed7",
   "metadata": {},
   "source": [
    "#### Propagation\n",
    "Ensemble methods obtain observation-parameter sensitivities from the covariances of the ensemble run through the model. Note that this for-loop is \"embarrasingly parallelizable\", because each iterate is complete indepdendent (requires no communication) from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012d7fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "multiprocess = False  # multiprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd274689",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def forward_model(nTime, wsats0, perms, Q_prod=None, desc=\"En. forecast\"):\n",
    "    \"\"\"Run forward model, i.e. forecast. Input args should be ensembles.\n",
    "\n",
    "    The main work consts of running the reservoir simulator\n",
    "    for each realisation in the ensemble.\n",
    "    However, the simulator only inputs/outputs state variables,\n",
    "    so we also have to take the necessary steps to set the parameter values\n",
    "    (implicitly used by the simulator). Setting parameter values\n",
    "    is as much part of the forward model as running the simulator.\n",
    "    \"\"\"\n",
    "    # Compose ensemble\n",
    "    if Q_prod is None:\n",
    "        E = zip(wsats0, perms)\n",
    "    else:\n",
    "        E = zip(wsats0, perms, Q_prod)\n",
    "\n",
    "    def forecast1(x):\n",
    "        # Since some parameters are implemented not as input/output of the model,\n",
    "        # but as instance attributes, there is a risk (especially with multiprocessing)\n",
    "        # that the values that are set for one member overwrites the values\n",
    "        # that should be used by another member. We will do a deepcopy to avoid this.\n",
    "        # Alternatively, we can re-initialize the model each time.\n",
    "        model_n = deepcopy(model)\n",
    "\n",
    "        if Q_prod is None:\n",
    "            wsat0, perm = x\n",
    "            # Set ensemble\n",
    "            set_perm(model_n, perm)\n",
    "        else:\n",
    "            wsat0, perm, q_prod = x\n",
    "            # Set production rates\n",
    "            model_n.config_wells(\n",
    "                inj  = model_n.injectors,\n",
    "                prod = np.hstack((wells, q_prod)),\n",
    "            )\n",
    "            # Set ensemble\n",
    "            set_perm(model_n, perm)\n",
    "\n",
    "        # Simulate\n",
    "        s, p = simulate(model_n.step, nTime, wsat0, dt, obs, pbar=False)\n",
    "        return s, p\n",
    "\n",
    "    # Allocate\n",
    "    production = np.zeros((N, nTime, nProd))\n",
    "    saturation = np.zeros((N, nTime+1, model.M))\n",
    "\n",
    "    # Dispatch\n",
    "    if multiprocess:\n",
    "        import multiprocessing_on_dill as mpd\n",
    "        with mpd.Pool() as pool:\n",
    "            E = list(progbar(pool.imap(forecast1, E), total=N, desc=desc))\n",
    "        # Write\n",
    "        for n, member in enumerate(E):\n",
    "            saturation[n], production[n] = member\n",
    "\n",
    "    else:\n",
    "        for n, xn in enumerate(progbar(list(E), \"Members\")):\n",
    "            s, p = forecast1(xn)\n",
    "            # Write\n",
    "            saturation[n], production[n] = s, p\n",
    "\n",
    "    return saturation, production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c1bcb",
   "metadata": {},
   "source": [
    "We also need to set the prior for the initial water saturation. As mentioned, this is not because it is uncertain/unknown; indeed, this case study assumes that it is perfectly known (i.e. equal to the true initial water saturation, which is a constant field of 0). However, in order to save one iteration, the posterior will also be output for the present-time water saturation (state) field, which is then used to restart simulations for future prediction (actually, the full time series of the saturation is output, but that is just for academic purposes). Therefore the forward_model must take water saturation as one of the inputs. Therefore, for the prior, we set this all to the true initial saturation (giving it uncertainty 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98799c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "wsat.initial.Prior = np.tile(wsat.initial.Truth, (N, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45ef34",
   "metadata": {},
   "source": [
    "Now we run the forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832c046",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "wsat.past.Prior, prod.past.Prior = forward_model(\n",
    "    nTime, wsat.initial.Prior, perm.Prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089a413",
   "metadata": {},
   "source": [
    "### Ensemble smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7d3e6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ES_update:\n",
    "    \"\"\"Update/conditioning (Bayes' rule) for an ensemble,\n",
    "\n",
    "    according to the \"ensemble smoother\" (ES) algorithm,\n",
    "\n",
    "    given a (vector) observations an an ensemble (matrix).\n",
    "\n",
    "    NB: obs_err_cov is treated as diagonal. Alternative: use `sla.sqrtm`.\n",
    "\n",
    "    Why have we chosen to use a class (and not a function)?\n",
    "    Because this allows storing `KGdY`, which we can then/later re-apply,\n",
    "    thereby enabling state-augmentation \"on-the-fly\".\n",
    "\n",
    "    NB: some of these formulea appear transposed, and reversed,\n",
    "    compared to (EnKF) literature standards. The reason is that\n",
    "    we stack the members as rows instead of the conventional columns.\n",
    "    Rationale: https://nansencenter.github.io/DAPPER/dapper/index.html#conventions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_ens, observation, obs_err_cov):\n",
    "        \"\"\"Prepare the update.\"\"\"\n",
    "        Y           = mean0(obs_ens)\n",
    "        obs_cov     = obs_err_cov*(N-1) + Y.T@Y\n",
    "        obs_pert    = randn(N, len(observation)) @ sqrt(obs_err_cov)\n",
    "        innovations = observation - (obs_ens + obs_pert)\n",
    "\n",
    "        # (pre-) Kalman gain * Innovations\n",
    "        self.KGdY = innovations @ sla.pinv2(obs_cov) @ Y.T\n",
    "\n",
    "    def __call__(self, E):\n",
    "        \"\"\"Do the update.\"\"\"\n",
    "        return E + self.KGdY @ mean0(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c599b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Update\n",
    "ES = ES_update(\n",
    "    obs_ens     = prod.past.Prior.reshape((N, -1)),\n",
    "    observation = prod.past.Noisy.reshape(-1),\n",
    "    obs_err_cov = sla.block_diag(*[R]*nTime),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5207f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply update\n",
    "perm.ES = ES(perm.Prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ec75c",
   "metadata": {},
   "source": [
    "#### Plot ES\n",
    "Let's plot the updated, initial ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a032a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plots.fields(model, 160, plots.field, perm.ES,\n",
    "             figsize=(14, 5), cmap=cmap,\n",
    "             title=\"ES posterior -- some realizations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee20e23",
   "metadata": {},
   "source": [
    "We will see some more diagnostics later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155cfa5",
   "metadata": {},
   "source": [
    "### Iterative ensemble smoother\n",
    "The following is (almost) all that distinguishes all of the fully-Bayesian iterative ensemble smoothers in the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ecf09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def iES_flavours(w, T, Y, Y0, dy, Cowp, za, N, nIter, itr, MDA, flavour):\n",
    "    N1 = N - 1\n",
    "    Cow1 = Cowp(1.0)\n",
    "\n",
    "    if MDA:  # View update as annealing (progressive assimilation).\n",
    "        Cow1 = Cow1 @ T  # apply previous update\n",
    "        dw = dy @ Y.T @ Cow1\n",
    "        if 'PertObs' in flavour:   # == \"ES-MDA\". By Emerick/Reynolds\n",
    "            D   = mean0(randn(*Y.shape)) * sqrt(nIter)\n",
    "            T  -= (Y + D) @ Y.T @ Cow1\n",
    "        elif 'Sqrt' in flavour:    # == \"ETKF-ish\". By Raanes\n",
    "            T   = Cowp(0.5) * sqrt(za) @ T\n",
    "        elif 'Order1' in flavour:  # == \"DEnKF-ish\". By Emerick\n",
    "            T  -= 0.5 * Y @ Y.T @ Cow1\n",
    "        Tinv = np.eye(N)  # [as initialized] coz MDA does not de-condition.\n",
    "\n",
    "    else:  # View update as Gauss-Newton optimzt. of log-posterior.\n",
    "        grad  = Y0@dy - w*za                  # Cost function gradient\n",
    "        dw    = grad@Cow1                     # Gauss-Newton step\n",
    "        # ETKF-ish\". By Bocquet/Sakov.\n",
    "        if 'Sqrt' in flavour:\n",
    "            # Sqrt-transforms\n",
    "            T     = Cowp(0.5) * sqrt(N1)\n",
    "            Tinv  = Cowp(-.5) / sqrt(N1)\n",
    "            # Tinv saves time [vs tinv(T)] when Nx<N\n",
    "        # \"EnRML\". By Oliver/Chen/Raanes/Evensen/Stordal.\n",
    "        elif 'PertObs' in flavour:\n",
    "            if itr == 0:\n",
    "                D = mean0(randn(*Y.shape))\n",
    "                iES_flavours.D = D\n",
    "            else:\n",
    "                D = iES_flavours.D\n",
    "            gradT = -(Y+D)@Y0.T + N1*(np.eye(N) - T)\n",
    "            T     = T + gradT@Cow1\n",
    "            # Tinv= tinv(T, threshold=N1)  # unstable\n",
    "            Tinv  = sla.inv(T+1)           # the +1 is for stability.\n",
    "        # \"DEnKF-ish\". By Raanes.\n",
    "        elif 'Order1' in flavour:\n",
    "            # Included for completeness; does not make much sense.\n",
    "            gradT = -0.5*Y@Y0.T + N1*(np.eye(N) - T)\n",
    "            T     = T + gradT@Cow1\n",
    "            Tinv  = sla.pinv2(T)\n",
    "\n",
    "    return dw, T, Tinv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f9605",
   "metadata": {},
   "source": [
    "This outer function loops through the iterations, forecasting, de/re-composing the ensemble, performing the linear regression, validating step, and making statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaba475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iES(ensemble, observation, obs_err_cov,\n",
    "        flavour=\"Sqrt\", MDA=False, bundle=False,\n",
    "        stepsize=1, nIter=10, wtol=1e-4):\n",
    "\n",
    "    E = ensemble\n",
    "    N = len(E)\n",
    "    N1 = N - 1\n",
    "    Rm12T = np.diag(sqrt(1/np.diag(obs_err_cov)))  # TODO?\n",
    "\n",
    "    stats = Dict()\n",
    "    stats.J_lklhd  = np.full(nIter, np.nan)\n",
    "    stats.J_prior  = np.full(nIter, np.nan)\n",
    "    stats.J_postr  = np.full(nIter, np.nan)\n",
    "    stats.rmse     = np.full(nIter, np.nan)\n",
    "    stats.stepsize = np.full(nIter, np.nan)\n",
    "    stats.dw       = np.full(nIter, np.nan)\n",
    "\n",
    "    if bundle:\n",
    "        if isinstance(bundle, bool):\n",
    "            EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I ...\n",
    "        else:\n",
    "            EPS = bundle\n",
    "    else:\n",
    "        EPS = 1.0  # ... prefer using  T=EPS*T, yielding a conditional cloud shape\n",
    "\n",
    "    # Init ensemble decomposition.\n",
    "    X0, x0 = center(E)    # Decompose ensemble.\n",
    "    w      = np.zeros(N)  # Control vector for the mean state.\n",
    "    T      = np.eye(N)    # Anomalies transform matrix.\n",
    "    Tinv   = np.eye(N)\n",
    "    # Explicit Tinv [instead of tinv(T)] allows for merging MDA code\n",
    "    # with iEnKS/EnRML code, and flop savings in 'Sqrt' case.\n",
    "\n",
    "    for itr in range(nIter):\n",
    "        # Reconstruct smoothed ensemble.\n",
    "        E = x0 + (w + EPS*T)@X0\n",
    "        stats.rmse[itr] = RMS(perm.Truth, E).rmse\n",
    "\n",
    "        # Forecast.\n",
    "        E_state, E_obs = forward_model(nTime, wsat.initial.Prior, E, desc=f\"Iteration {itr}\")\n",
    "        E_obs = E_obs.reshape((N, -1))\n",
    "\n",
    "        # Undo the bundle scaling of ensemble.\n",
    "        if EPS != 1.0:\n",
    "            E     = inflate_ens(E, 1/EPS)\n",
    "            E_obs = inflate_ens(E_obs, 1/EPS)\n",
    "\n",
    "        # Prepare analysis.Ç\n",
    "        y      = observation        # Get current obs.\n",
    "        Y, xo  = center(E_obs)      # Get obs {anomalies, mean}.\n",
    "        dy     = (y - xo) @ Rm12T   # Transform obs space.\n",
    "        Y      = Y        @ Rm12T   # Transform obs space.\n",
    "        Y0     = Tinv @ Y           # \"De-condition\" the obs anomalies.\n",
    "\n",
    "        # Set \"cov normlzt fctr\" za (\"effective ensemble size\")\n",
    "        # => pre_infl^2 = (N-1)/za.\n",
    "        za = N1\n",
    "        if MDA:\n",
    "            # inflation (factor: nIter) of the ObsErrCov.\n",
    "            za *= nIter\n",
    "\n",
    "        # Compute Cowp: the (approx) posterior cov. of w\n",
    "        # (estiamted at this iteration), raised to some power.\n",
    "        V, s, UT = svd0(Y0)\n",
    "        def Cowp(expo): return (V * (pad0(s**2, N) + za)**-expo) @ V.T\n",
    "\n",
    "        # TODO: NB: these stats are only valid for Sqrt\n",
    "        stat2 = Dict(\n",
    "            J_prior = w@w * N1,\n",
    "            J_lklhd = dy@dy,\n",
    "        )\n",
    "        # J_posterior is sum of the other two\n",
    "        stat2.J_postr = stat2.J_prior + stat2.J_lklhd\n",
    "        # Take root, insert for [itr]:\n",
    "        for name in stat2:\n",
    "            stats[name][itr] = sqrt(stat2[name])\n",
    "\n",
    "        # Accept previous increment? ...\n",
    "        if (not MDA) and itr > 0 and stats.J_postr[itr] > np.nanmin(stats.J_postr):\n",
    "            # ... No. Restore previous ensemble & lower the stepsize (dont compute new increment).\n",
    "            stepsize   /= 10\n",
    "            w, T, Tinv  = old  # noqa\n",
    "        else:\n",
    "            # ... Yes. Store this ensemble, boost the stepsize, and compute new increment.\n",
    "            old         = w, T, Tinv\n",
    "            stepsize   *= 2\n",
    "            stepsize    = min(1, stepsize)\n",
    "            dw, T, Tinv = iES_flavours(w, T, Y, Y0, dy, Cowp, za, N, nIter, itr, MDA, flavour)\n",
    "\n",
    "        stats.      dw[itr] = dw@dw / N\n",
    "        stats.stepsize[itr] = stepsize\n",
    "\n",
    "        # Step\n",
    "        w = w + stepsize*dw\n",
    "\n",
    "        if stepsize * np.sqrt(dw@dw/N) < wtol:\n",
    "            break\n",
    "\n",
    "    stats.nIter = itr + 1\n",
    "\n",
    "    if not MDA:\n",
    "        # The last step (dw, T) must be discarded,\n",
    "        # because it cannot be validated without re-running the model.\n",
    "        w, T, Tinv  = old\n",
    "\n",
    "    # Reconstruct the ensemble.\n",
    "    E = x0 + (w+T)@X0\n",
    "\n",
    "    return E, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e12a91",
   "metadata": {},
   "source": [
    "#### Apply the iES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927fefa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "perm.iES, stats_iES = iES(\n",
    "    ensemble = perm.Prior,\n",
    "    observation = prod.past.Noisy.reshape(-1),\n",
    "    obs_err_cov = sla.block_diag(*[R]*nTime),\n",
    "    flavour=\"Sqrt\", MDA=False, bundle=False, stepsize=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd11b5",
   "metadata": {},
   "source": [
    "#### Plot iES\n",
    "Let's plot the updated, initial ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee019c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.fields(model, 165, plots.field, perm.iES,\n",
    "             figsize=(14, 5), cmap=cmap,\n",
    "             title=\"iES posterior -- some realizations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57965b82",
   "metadata": {},
   "source": [
    "The following plots the cost function(s) together with the error compared to the true (pre-)perm field as a function of the iteration number. Note that the relationship between the (total, i.e. posterior) cost function  and the RMSE is not necessarily monotonic. Re-running the experiments with a different seed is instructive. It may be observed that the iterations are not always very successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = freshfig(167)\n",
    "ls = dict(J_prior=\":\", J_lklhd=\"--\", J_postr=\"-\")\n",
    "for name, J in stats_iES.items():\n",
    "    try:\n",
    "        ax.plot(J, color=\"b\", label=name.split(\"J_\")[1], ls=ls[name])\n",
    "    except IndexError:\n",
    "        pass\n",
    "ax.set_xlabel(\"iteration\")\n",
    "ax.set_ylabel(\"RMS mismatch\", color=\"b\")\n",
    "ax.tick_params(axis='y', labelcolor=\"b\")\n",
    "ax.legend()\n",
    "ax2 = ax.twinx()  # axis for rmse\n",
    "ax2.set_ylabel('RMS error', color=\"r\")\n",
    "ax2.plot(stats_iES.rmse, color=\"r\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"r\")\n",
    "plt.pause(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2113796",
   "metadata": {},
   "source": [
    "### Diagnostics\n",
    "In terms of root-mean-square error (RMSE), the ES is expected to improve on the prior. The \"expectation\" wording indicates that this is true on average, but not always. To be specific, it means that it is guaranteed to hold true if the RMSE is calculated for infinitely many experiments (each time simulating a new synthetic truth and observations from the prior). The reason for this is that the ES uses the Kalman update, which is the BLUE (best linear unbiased estimate), and \"best\" means that the variance must get reduced. However, note that this requires the ensemble to be infinitely big, which it most certainly is not in our case. Therefore, we do not need to be very unlucky to observe that the RMSE has actually increased. Despite this, as we will see later, the data match might yield a different conclusions concerning the utility of the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stats vs. true field\")\n",
    "RMS_all(perm, vs=\"Truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee7514",
   "metadata": {},
   "source": [
    "### Plot of means\n",
    "Let's plot mean fields.\n",
    "\n",
    "NB: Caution! Mean fields are liable to be less rugged than the truth. As such, their importance must not be overstated (they're just one esitmator out of many). Instead, whenever a decision is to be made, all of the members should be included in the decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0429a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm._means = Dict((k, perm[k].mean(axis=0)) for k in perm if not k.startswith(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ba7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.fields(model, 170, plots.field, perm._means,\n",
    "             figsize=(14, 5), cmap=cmap,\n",
    "             title=\"Truth and mean fields.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a87aff",
   "metadata": {},
   "source": [
    "### Past production (data mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b53577",
   "metadata": {},
   "source": [
    "We already have the past true and prior production profiles. Let's add to that the production profiles of the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsat.past.ES, prod.past.ES = forward_model(nTime, wsat.initial.Prior, perm.ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3564bd1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "wsat.past.iES, prod.past.iES = forward_model(nTime, wsat.initial.Prior, perm.iES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a0511",
   "metadata": {},
   "source": [
    "We can also apply the ES update (its X5 matrix, for those familiar with that terminology) directly to the production data of the prior, which doesn't require running the model again (like we did immediately above). Let us try that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d597332",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ravelled(fun, xx):\n",
    "    shape = xx.shape\n",
    "    xx = xx.reshape((shape[0], -1))\n",
    "    yy = fun(xx)\n",
    "    return yy.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfc258",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "prod.past.ES0 = ravelled(ES, prod.past.Prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea1935",
   "metadata": {},
   "source": [
    "Plot them all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook/NbAgg backend fails after a few toggles\n",
    "%matplotlib inline\n",
    "\n",
    "v = plots.productions(prod.past, 175, figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4944b",
   "metadata": {},
   "source": [
    "#### Data mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12afb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stats vs. past production (i.e. NOISY observations)\")\n",
    "RMS_all(prod.past, vs=\"Noisy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f68575",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Note that the data mismatch is significantly reduced. This may be the case even if the updated permeability field did not have a reduced rmse (overall, relative to that of the prior prior). The \"direct\" forecast (essentially just linear regression) may achieve even lower rmse, but generally, less realistic production plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715ab23",
   "metadata": {},
   "source": [
    "##### Comment on prior\n",
    "Note that the prior \"surrounds\" the data. This the likely situation in our synthetic case, where the truth was generated by the same random draw process as the ensemble.\n",
    "\n",
    "In practice, this is often not the case. If so, you might want to go back to your geologists and tell them that something is amiss. You should then produce a revised prior with better properties.\n",
    "\n",
    "Note: the above instructions sound like statistical heresy. We are using the data twice over (on the prior, and later to update/condition the prior). However, this is justified to the extent that prior information is difficult to quantify and encode. Too much prior adaptation, however, and you risk overfitting! Ineed, it is a delicate matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a62c75",
   "metadata": {},
   "source": [
    "##### Comment on posterior\n",
    "If the assumptions (statistical indistinguishability, Gaussianity) are not too far off, then the ensemble posteriors (ES, EnKS, ES0) should also surround the data, but with a tighter fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d0d96",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "We now prediction the future production (and saturation fields) by forecasting using the (updated) estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f70484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Future/prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26288a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsat.future.Truth, prod.future.Truth = simulate(\n",
    "    model.step, nTime, wsat.past.Truth[-1], dt, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsat.future.Prior, prod.future.Prior = forward_model(\n",
    "    nTime, wsat.past.Prior[:, -1, :], perm.Prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ba637",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsat.future.ES, prod.future.ES = forward_model(\n",
    "    nTime, wsat.past.ES[:, -1, :], perm.ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc89386",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsat.future.iES, prod.future.iES = forward_model(\n",
    "    nTime, wsat.past.iES[:, -1, :], perm.iES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.future.ES0 = ravelled(ES, prod.future.Prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147226a9",
   "metadata": {},
   "source": [
    "#### Plot future production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd99950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.productions(prod.future, 200, figsize=(14, 5), title=\"-- Future\");\n",
    "plt.pause(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a6ce1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Stats vs. (supposedly unknown) future production\")\n",
    "RMS_all(prod.future, vs=\"Truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cdb0a",
   "metadata": {},
   "source": [
    "## EnOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2e3c9",
   "metadata": {},
   "source": [
    "This section is still in construction. There are many details missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483f372",
   "metadata": {},
   "source": [
    "Cost function definition: total oil from production wells. This cost function takes for an ensemble of (wsat, perm) and controls (Q_prod) and outputs the corresponding ensemble of total oil productions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb16db0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def total_oil(E, Eu):\n",
    "    wsat, perm = E\n",
    "    wsat, prod = forward_model(nTime, wsat, perm, Q_prod=Eu)\n",
    "    return np.sum(prod, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c3c07",
   "metadata": {},
   "source": [
    "Define step modulator by adding momentum to vanilla gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfeb29b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def GDM(beta1=0.9):\n",
    "    \"\"\"Gradient descent with (historical) momentum.\"\"\"\n",
    "    grad1 = 0\n",
    "\n",
    "    def set_historical(g):\n",
    "        nonlocal grad1\n",
    "        grad1 = beta1*grad1 + (1-beta1)*g\n",
    "\n",
    "    def step(g):\n",
    "        set_historical(g)\n",
    "        return grad1\n",
    "\n",
    "    return step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3ebdc",
   "metadata": {},
   "source": [
    "Define EnOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ce9bd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def EnOpt(wsats0, perms, u, C12, stepsize=1, nIter=10):\n",
    "    N = len(wsats0)\n",
    "    E = wsats0, perms\n",
    "\n",
    "    stepper = GDM()\n",
    "\n",
    "    print(\"Initial controls:\", u)\n",
    "    J = total_oil(E, np.tile(u, (N, 1))).mean()\n",
    "    print(\"Total oil, averaged, initial: %.3f\" % J)\n",
    "\n",
    "    for _itr in progbar(range(nIter), desc=\"EnOpt\"):\n",
    "        Eu = u + randn(N, len(u)) @ C12.T\n",
    "        Eu = Eu.clip(1e-5)\n",
    "\n",
    "        Ej = total_oil(E, Eu)\n",
    "        # print(\"Approx. total oil, average: %.3f\"%Ej.mean())\n",
    "\n",
    "        Xu = mean0(Eu)\n",
    "        Xj = mean0(Ej)\n",
    "\n",
    "        G  = Xj.T @ Xu / (N-1)\n",
    "\n",
    "        du = stepper(G)\n",
    "        u  = u + stepsize*du\n",
    "        u  = u.clip(1e-5)\n",
    "\n",
    "    print(\"Final controls:\", u)\n",
    "    J = total_oil(E, np.tile(u, (N, 1))).mean()\n",
    "    print(\"Total oil, averaged, final: %.3f\" % J)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55912bfb",
   "metadata": {},
   "source": [
    "Run EnOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u0  = model.producers[:, 2]\n",
    "u0  = np.random.rand(nProd)\n",
    "u0 /= sum(u0)\n",
    "C12 = 0.03 * np.eye(nProd)\n",
    "u   = EnOpt(wsat.past.ES[:, -1, :], perm.ES, u0, C12, stepsize=10)\n",
    "# u   = EnOpt(wsat.past.iES[:, -1, :], perm.iES, u0, C12, stepsize=10)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "auto:light,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
